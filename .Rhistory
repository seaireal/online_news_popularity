points(3, bwdsum$bic[3])
plot(fwdsum$adjr2, xlab = "Subset Size", ylab = "Forward Adjusted R2",  pch = 20, type = "l")
points(3, fwdsum$adjr2[3])
plot(bwdsum$adjr2, xlab = "Subset Size", ylab = "Backward Adjusted R2", pch = 20, type = "l")
points(3, bwdsum$adjr2[3])
#Plot the statistics
par(mfrow = c(3, 2))
plot(fwdsum$cp, xlab = "Subset Size", ylab = "Forward Cp", pch = 20, type = "l")
points(3, fwdsum$cp[3])
plot(bwdsum$cp, xlab = "Subset Size", ylab = "Backward Cp", pch = 20, type = "l")
points(3, bwdsum$cp[3])
plot(fwdsum$bic, xlab = "Subset Size", ylab = "Forward BIC", pch = 20, type = "l")
points(3, fwdsum$bic[3])
plot(bwdsum$bic, xlab = "Subset Size", ylab = "Backward BIC", pch = 20, type = "l")
points(3, bwdsum$bic[3])
plot(fwdsum$adjr2, xlab = "Subset Size", ylab = "Forward Adjusted R2",  pch = 20, type = "l")
points(3, fwdsum$adjr2[3])
plot(bwdsum$adjr2, xlab = "Subset Size", ylab = "Backward Adjusted R2", pch = 20, type = "l")
points(3, bwdsum$adjr2[3])
#Coefficients of the best model obtained.
coefficients(mod, id = 3)
# Plot cp, BIC and adjr2
par(mfrow = c(2, 2))
plot(summ$cp, xlab = "Subset Size", ylab = "Cp", pch = 20, type = "l")
points(3, summ$cp[3])
plot(summ$bic, xlab = "Subset Size", ylab = "BIC", pch = 20, type = "l")
points(3, summ$bic[3])
plot(summ$adjr2, xlab = "Subset Size", ylab = "Adjusted R squared", pch = 20, type = "l")
points(3, summ$adjr2[3])
coefficients(fwd, id = 3)
coefficients(bwd, id = 3)
xdf = model.matrix(y1 ~ poly(x1, 10, raw = T), data = df)[, -1]
lasso = cv.glmnet(xdf, Y, alpha = 1)
lambda = lasso$lambda.min
lambda
xdf = model.matrix(y1 ~ poly(x1, 10, raw = T), data = df)[, -1]
lasso = cv.glmnet(xdf, Y, alpha = 1)
lambda = lasso$lambda.min
lambda
plot(lasso)
#the resulting coefficient estimates
newmod = glmnet(xdf, Y, alpha = 1)
predict(newmod, s = lambda, type = "coefficients")
b0 = 0.5
b1 = 1.2
b2 = 2.5
b3 = 3
Y = b0 + b1 * X + b2 * X^2 + b3 * X^3 + er
library(leaps)
df = data.frame(y1 = Y, x1 = X)
mod = regsubsets(y1 ~ poly(x1, 10, raw = T), data = df, nvmax = 10)
summ = summary(mod)
# Find the best model size based on cp, BIC and adjr2
which.min(summ$cp)
which.min(summ$bic)
which.max(summ$adjr2)
#Coefficients of the best model obtained.
coefficients(mod, id = 4)
coefficients(mod, id = 3)
# Plot cp, BIC and adjr2
par(mfrow = c(2, 2))
plot(summ$cp, xlab = "Subset Size", ylab = "Cp", pch = 20, type = "l")
points(3, summ$cp[3])
plot(summ$bic, xlab = "Subset Size", ylab = "BIC", pch = 20, type = "l")
points(3, summ$bic[3])
plot(summ$adjr2, xlab = "Subset Size", ylab = "Adjusted R squared", pch = 20, type = "l")
points(3, summ$adjr2[3])
#Coefficients of the best model obtained.
coefficients(mod, id = 4)
coefficients(mod, id = 3)
# Plot cp, BIC and adjr2
par(mfrow = c(3, 2))
plot(summ$cp, xlab = "Subset Size", ylab = "Cp", pch = 20, type = "l")
points(3, summ$cp[3])
plot(summ$bic, xlab = "Subset Size", ylab = "BIC", pch = 20, type = "l")
points(3, summ$bic[3])
plot(summ$adjr2, xlab = "Subset Size", ylab = "Adjusted R squared", pch = 20, type = "l")
points(3, summ$adjr2[3])
fwd = regsubsets(y1 ~ poly(x1, 10, raw = T), data = df, nvmax = 10,
method = "forward")
bwd = regsubsets(y1 ~ poly(x1, 10, raw = T), data = df, nvmax = 10,
method = "backward")
fwdsum = summary(fwd)
bwdsum = summary(bwd)
which.min(fwdsum$cp)
which.min(bwdsum$cp)
which.min(fwdsum$bic)
which.min(bwdsum$bic)
which.max(fwdsum$adjr2)
which.max(bwdsum$adjr2)
coefficients(fwd, id = 3)
coefficients(bwd, id = 3)
coefficients(fwd, id = 4)
coefficients(bwd, id = 4)
#Plot the statistics
par(mfrow = c(3, 2))
plot(fwdsum$cp, xlab = "Subset Size", ylab = "Forward Cp", pch = 20, type = "l")
points(3, fwdsum$cp[3])
plot(bwdsum$cp, xlab = "Subset Size", ylab = "Backward Cp", pch = 20, type = "l")
points(3, bwdsum$cp[3])
plot(fwdsum$bic, xlab = "Subset Size", ylab = "Forward BIC", pch = 20, type = "l")
points(3, fwdsum$bic[3])
plot(bwdsum$bic, xlab = "Subset Size", ylab = "Backward BIC", pch = 20, type = "l")
points(3, bwdsum$bic[3])
plot(fwdsum$adjr2, xlab = "Subset Size", ylab = "Forward Adjusted R2",  pch = 20, type = "l")
points(3, fwdsum$adjr2[3])
plot(bwdsum$adjr2, xlab = "Subset Size", ylab = "Backward Adjusted R2", pch = 20, type = "l")
points(3, bwdsum$adjr2[3])
#Coefficients of the best model obtained.
coefficients(mod, id = 4)
coefficients(mod, id = 3)
# Plot cp, BIC and adjr2
par(mfrow = c(3, 2))
plot(summ$cp, xlab = "Subset Size", ylab = "Cp", pch = 20, type = "l")
points(3, summ$cp[3])
plot(summ$bic, xlab = "Subset Size", ylab = "BIC", pch = 20, type = "l")
points(3, summ$bic[3])
plot(summ$adjr2, xlab = "Subset Size", ylab = "Adjusted R squared", pch = 20, type = "l")
points(3, summ$adjr2[3])
xdf = model.matrix(y1 ~ poly(x1, 10, raw = T), data = df)[, -1]
lasso = cv.glmnet(xdf, Y, alpha = 1)
lambda = lasso$lambda.min
lambda
plot(lasso)
#the resulting coefficient estimates
newmod = glmnet(xdf, Y, alpha = 1)
predict(newmod, s = lambda, type = "coefficients")
b7 = 5
Y = b0 + b7 * X^7 + er
# Predict using regsubsets
df2 = data.frame(y2 = Y, x2 = X)
mod2 = regsubsets(y2 ~ poly(x2, 10, raw = T), data = df2, nvmax = 10)
modsum2 = summary(mod.full)
b7 = 5
Y = b0 + b7 * X^7 + er
# Predict using regsubsets
df2 = data.frame(y2 = Y, x2 = X)
mod2 = regsubsets(y2 ~ poly(x2, 10, raw = T), data = df2, nvmax = 10)
modsum2 = summary(mod2)
# Find the model size for best cp, BIC and adjr2
which.min(modsum2$cp)
## [1] 2
which.min(modsum2$bic)
## [1] 1
which.max(modsum2$adjr2)
coefficients(mod2, id = 2)
coefficients(mod2, id = 1)
coefficients(mod2, id = 4)
# Predict using lasso
xdf2 = model.matrix(y2 ~ poly(x2, 10, raw = T), data = df2)[, -1]
lasso2 = cv.glmnet(xdf2, Y2, alpha = 1)
# Predict using lasso
xdf2 = model.matrix(y2 ~ poly(x2, 10, raw = T), data = df2)[, -1]
lasso2 = cv.glmnet(xdf2, Y, alpha = 1)
lambda2 = lasso2$lambda.min
lambda2
best.model = glmnet(xmat, Y, alpha = 1)
# Predict using lasso
xdf2 = model.matrix(y2 ~ poly(x2, 10, raw = T), data = df2)[, -1]
lasso2 = cv.glmnet(xdf2, Y, alpha = 1)
lambda2 = lasso2$lambda.min
newmod2 = glmnet(xdf2, Y, alpha = 1)
predict(newmod2, s = lambda2, type = "coefficients")
# Predict using lasso
xdf2 = model.matrix(y2 ~ poly(x2, 10, raw = T), data = df2)[, -1]
lasso2 = cv.glmnet(xdf2, Y, alpha = 1)
lambda2 = lasso2$lambda.min
newmod2 = glmnet(xdf2, Y, alpha = 1)
predict(newmod2, s = lambda2, type = "coefficients")
#train ridge coefficients
library (glmnet)
ridge <- glmnet(x[-test,],y[-test,],alpha =0, lambda =0.01)
ridge.pred=predict(ridge,s=0.01, newx=x[test ,])
mean((ridge.pred-ytest)^2)
#split data into 10 folds, one of which being the test data
set.seed (1)
test=sample (1: nrow(x), nrow(x)/10)
ytest=y[test,]
xtest=x[test,]
xtrain=x[-test,]
ytrain=y[-test,]
#train ridge coefficients
library (glmnet)
ridge <- glmnet(x[-test,],y[-test,],alpha =0, lambda =0.01)
ridge.pred=predict(ridge,s=0.01, newx=x[test ,])
mean((ridge.pred-ytest)^2)
#split data into 10 folds, one of which being the test data
set.seed (1)
test=sample (1: nrow(x), nrow(x)/10)
ytest=y[test,]
xtest=x[test,]
xtrain=x[-test,]
ytrain=y[-test,]
#train ridge coefficients
library (glmnet)
ridge <- glmnet(x[-test,],y[-test,],alpha =0, lambda =0.01)
ridge.pred=predict(ridge,s=0.01, newx=x[test ,])
mean((ridge.pred-ytest)^2)
library(ISLR)
summary(Hitters)
Hitters=na.omit(Hitters)
with(Hitters,sum(is.na(Salary)))
library(leaps)
regfit.full=regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],pch=20,col="red")
plot(regfit.full,scale="Cp")
coef(regfit.full,10)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
dim(Hitters)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors),ylab="Root MSE",ylim=c(300,400),pch=19,type="b")
points(sqrt(regfit.fwd$rss[-1]/180),col="blue",pch=19,type="b")
legend("topright",legend=c("Training","Validation"),col=c("blue","black"),pch=19)
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds=sample(rep(1:10,length=nrow(Hitters)))
folds
table(folds)
cv.errors=matrix(NA,10,19)
for(k in 1:10){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=k,],nvmax=19,method="forward")
for(i in 1:19){
pred=predict(best.fit,Hitters[folds==k,],id=i)
cv.errors[k,i]=mean( (Hitters$Salary[folds==k]-pred)^2)
}
}
rmse.cv=sqrt(apply(cv.errors,2,mean))
plot(rmse.cv,pch=19,type="b")
library(glmnet)
x=model.matrix(Salary~.-1,data=Hitters)
y=Hitters$Salary
fit.ridge=glmnet(x,y,alpha=0)
plot(fit.ridge,xvar="lambda",label=TRUE)
cv.ridge=cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
fit.lasso=glmnet(x,y)
plot(fit.lasso,xvar="lambda",label=TRUE)
cv.lasso=cv.glmnet(x,y)
plot(cv.lasso)
coef(cv.lasso)
lasso.tr=glmnet(x[train,],y[train])
lasso.tr
pred=predict(lasso.tr,x[-train,])
dim(pred)
rmse= sqrt(apply((y[-train]-pred)^2,2,mean))
plot(log(lasso.tr$lambda),rmse,type="b",xlab="Log(lambda)")
lam.best=lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr,s=lam.best)
ridge$rss[-1]
library(tidyverse)
library(extraDistr)
# generate data
set.seed(1000)
x <- rsign(10^7) %>% matrix(nrow = 1000, ncol = 10000)
e <- rnorm(1000,0,1) %>% matrix(nrow = 1000, ncol = 1)
b <- matrix(1,nrow = 10000,ncol = 1,byrow = TRUE)
y <- x%*%b + e
#split data into 10 folds, one of which being the test data
set.seed (1)
test=sample (1: nrow(x), nrow(x)/10)
ytest=y[test,]
xtest=x[test,]
xtrain=x[-test,]
ytrain=y[-test,]
#train ridge coefficients
library (glmnet)
ridge <- glmnet(x[-test,],y[-test,],alpha =0, lambda =0.01)
#estimate test error
ridge.pred=predict(ridge,s=0.01, newx=x[test ,])
mean((ridge.pred-ytest)^2)
$rss[-1]
ridge$rss[-1]
ridge$rss
a=c(0,1,2,3)
a^2
1+a^2
b-coef(rtrain)[-1]
a[-1]
?rbinom
rbinom(1000,0.3)
rbinom(1000,prob=0.3)
rbinom(1000,1,0.3)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
a <- rbinom(1000,1,0.3)
x <- rnorm(1000,0,1)
e <- rnorm(1000,0,1)
y <- 2+0*a+3*x+e
lm(y~a+x)
summary(lm(y~a+x))
summary(lm(y~a+x))
lm_sum=summary(lm(y~a+x))
lm_sum=summary(lm(y~a+x))
c("lower" = lm_sum$coef[2,1] - qt(0.975, df = lm_sum$df[2]) * lm_sum$coef[2, 2],
"upper" = lm_sum$coef[2,1] + qt(0.975, df = lm_summ$df[2]) * lm_sum$coef[2, 2])
lm_sum=summary(lm(y~a+x))
c("lower" = lm_sum$coef[2,1] - qt(0.975, df = lm_sum$df[2]) * lm_sum$coef[2, 2],
"upper" = lm_sum$coef[2,1] + qt(0.975, df = lm_sum$df[2]) * lm_sum$coef[2, 2])
lm_sum$coef[2,1]
lm_sum=summary(lm(y~a+x))
c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],
"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2])
lm_sum=summary(lm(y~a+x))
c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],
"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2])
CI={}
for (i in 1:1000) {
lm_sum=summary(lm(y~a+x))
rbind(CI,c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2]))
}
CI
lm_sum=summary(lm(y~a+x))
c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],
"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2])
CI={}
for (i in 1:1000) {
i=i+1
lm_sum=summary(lm(y~a+x))
rbind(CI,c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2]))
}
CI
lm_sum=summary(lm(y~a+x))
c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],
"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2])
ci={}
for (i in 1:1000) {
lm_sum=summary(lm(y~a+x))
ci=rbind(ci,c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2]))
}
ci
View(ci)
sum(ci$lower<=0&ci$upper>=0)
sum(ci[,1]<=0&ci[,2]>=0)
ci[,1]<=0&ci[,2]>=0
View(ci)
View(ci)
lm(y~a+x)
lm(y~a+x)
ci={}
for (i in 1:1000) {
a <- rbinom(1000,1,0.3)
x <- rnorm(1000,0,1)
e <- rnorm(1000,0,1)
y <- 2+0*a+3*x+e
lm_sum=summary(lm(y~a+x))
ci=rbind(ci,c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2]))
}
sum(ci[,1]<=0&ci[,2]>=0)
ci={}
for (i in 1:1000) {
set.seed(1)
a <- rbinom(1000,1,0.3)
x <- rnorm(1000,0,1)
e <- rnorm(1000,0,1)
y <- 2+0*a+3*x+e
lm_sum=summary(lm(y~a+x))
ci=rbind(ci,c("lower" = lm_sum$coef[2,1] - qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2],"upper" = lm_sum$coef[2,1] + qt(0.95, df = lm_sum$df[2]) * lm_sum$coef[2, 2]))
}
sum(ci[,1]<=0&ci[,2]>=0)
library(tidyverse)
library(extraDistr)
library(pls)
library (glmnet)
library(boot)
library(foreign)
library(Matching)
require(Matching)
require(Matching)
?matching
install.packages("Matching")
library(Matching)
knitr::opts_chunk$set(echo = TRUE)
df = read.table("OnlineNewsPopularity.xls", header = TRUE)
df = read.table("OnlineNewsPopularity.xls", header = TRUE)
df = read.table("OnlineNewsPopularity.xls", header = TRUE)
df = read.table("OnlineNewsPopularity.xls", header = TRUE)
library(tidyverse)
library(readxl)
library(extraDistr)
library(ISLR)
library(glmnet)
library(pls)
library(boot)
df = read_excel("OnlineNewsPopularity.xls", header = TRUE)
df = read_excel("OnlineNewsPopularity.xls")
df = read_excel(OnlineNewsPopularity.xls)
getwd()
library(tidyverse)
library(readxl)
library(extraDistr)
library(ISLR)
library(glmnet)
library(pls)
library(boot)
setwd("C:\Users\conta\Google Drive\DATA MINING\project\online_news_popularity")
library(tidyverse)
library(readxl)
library(extraDistr)
library(ISLR)
library(glmnet)
library(pls)
library(boot)
setwd("C:\\Users\\conta\\Google Drive\\DATA MINING\\project\\online_news_popularity")
df = read_excel(OnlineNewsPopularity.xls)
df = read_excel("OnlineNewsPopularity.xls")
df = read_excel(OnlineNewsPopularity)
df = read_excel(OnlineNewsPopularity.csv)
df = read_excel("OnlineNewsPopularity.csv")
df = read_excel("OnlineNewsPopularity.xls")
df = read_excel("OnlineNewsPopularity.xlsx")
df = read_excel("OnlineNewsPopularity.cvs")
df = read_excel("OnlineNewsPopularity")
df = read_excel(OnlineNewsPopularity)
df = read_excel(OnlineNewsPopularity.csv)
df = read_excel(OnlineNewsPopularity.xls)
df = read_excel(OnlineNewsPopularity.xlsx)
df = read_excel('OnlineNewsPopularity.xls')
df = read_excel('OnlineNewsPopularity.xlsx')
df = read_excel('OnlineNewsPopularity.csv')
readxl_example()
df = read_excel(https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv)
df = read_excel('https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv')
temp = tempfile(fileext = ".xlsx")
dataURL <- "https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv"
download.file(dataURL, destfile=temp, mode='wb')
df = read_excel(temp)
temp = tempfile(fileext = ".xlsx")
dataURL <- "https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv"
download.file(dataURL, destfile=temp, mode='wb')
df = read_excel(temp)
temp = tempfile(fileext = ".csv")
dataURL <- "https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv"
download.file(dataURL, destfile=temp, mode='wb')
df = read_excel(temp)
#temp = tempfile(fileext = ".csv")
dataURL <- "https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv"
#download.file(dataURL, destfile=temp, mode='wb')
df = read_excel(dataURL)
#temp = tempfile(fileext = ".csv")
dataURL <- "https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv"
#download.file(dataURL, destfile=temp, mode='wb')
df = read_html(dataURL)
library(tidyverse)
library(readxl)
library(rvest)
library(extraDistr)
library(ISLR)
library(glmnet)
library(pls)
library(boot)
# setwd("C:\\Users\\conta\\Google Drive\\DATA MINING\\project\\online_news_popularity")
#temp = tempfile(fileext = ".csv")
dataURL <- "https://github.com/seaireal/online_news_popularity/blob/master/OnlineNewsPopularity.csv"
#download.file(dataURL, destfile=temp, mode='wb')
df = read_html(dataURL)
View(df)
setwd("C:\\Users\\conta\\Google Drive\\DATA MINING\\project\\online_news_popularity")
df = read_excel("OnlineNewsPopularity.csv")
df = read_excel("OnlineNewsPopularity.xls")
df = read_excel("OnlineNewsPopularity.csv")
df = read_csv("OnlineNewsPopularity.csv")
spec(...)
?read_csv
df = read_csv(OnlineNewsPopularity.csv)
df = read_csv("OnlineNewsPopularity.csv")
View(df)
plot(df)
plot(df$timedelta)
plot(df$n_tokens_title)
hist(df$n_tokens_title)
plot(df$n_tokens_content)
hist(df$n_tokens_content)
hist(df)
table(df)
for (i in 1:61) {
hist(df[,i])
}
hist(df[,1])
hist(df[1,])
hist(df[[1]])
df[[1]]
for (i in 2:61) {
hist(df[,i])
}
hist(df[[2]])
for (i in 2:61) {
hist(df[[i]])
}
